{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureImages(name,path):\n",
    "    try:\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        capture = False\n",
    "\n",
    "        cv2.namedWindow(\"Capturing Images ...\")\n",
    "\n",
    "        img_counter = 0\n",
    "        timeout = time.time() + 60*1   # 5 minutes from now\n",
    "        while True:\n",
    "            test = 0\n",
    "            if test == 3 or time.time() > timeout:\n",
    "                break\n",
    "            test = test - 1\n",
    "            ret, frame = cam.read()\n",
    "            cv2.imshow(\"Capturing Images from different angles\", frame)\n",
    "            if not ret:\n",
    "                break\n",
    "            k = cv2.waitKey(1)\n",
    "            if img_counter==20:  # Change the number of Images to capture \n",
    "                break;\n",
    "            if k%256 == 27:\n",
    "                # ESC pressed\n",
    "                print(\"Escape hit, closing...\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "            capture = True\n",
    "            if capture:\n",
    "                img_name = \"{}.jpg\".format(img_counter)\n",
    "                cv2.imwrite(os.path.join(path , img_name),frame)\n",
    "                img_counter += 1\n",
    "                capture = False\n",
    "\n",
    "        cam.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        track = traceback.format_exc()\n",
    "        print(track)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registerUser(UserName):\n",
    "    path = registerDirectoryPath + UserName\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "        if captureImages(UserName,path):\n",
    "            print(UserName + ' is registered')\n",
    "            return True\n",
    "        else:\n",
    "            print(UserName + ' is not successfully registered')\n",
    "            return False\n",
    "    except OSError:\n",
    "        print (\"Creation of the register directory %s failed\" % path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFacesFromRegisteredImages(gray,frame):\n",
    "    global region_of_interest_frame\n",
    "    global face_cascade\n",
    "    region_of_interest_frame = None\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray,1.05,6)   #Returns 4 arguments x,y coordinate of top left corner and width and height\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x-50,y-50),(x+w+50,y+h+50),(255,0,0),2)\n",
    "        region_of_interest_gray = gray[y:y+h,x:x+w]   # Cascade will be applied in gray scaled version of region of  interest\n",
    "        region_of_interest_frame = frame[y-50:y+h+50,x-50:x+w+50] # Rectangle will be drawn to colored version of area of interset\n",
    "        \n",
    "    return frame,region_of_interest_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(userName):\n",
    "    sourcePath = registerDirectoryPath + userName\n",
    "    #print(sourcePath)\n",
    "    path = trainingDirectoryPath + userName\n",
    "    #print(path)\n",
    "    try:\n",
    "        image_files = [file for file in listdir(sourcePath) if isfile(join(sourcePath,file))]\n",
    "        os.makedirs(path)\n",
    "        for i,image in enumerate(image_files):\n",
    "            actualImage = cv2.imread(sourcePath + '\\\\' + image)\n",
    "            grayImage = cv2.cvtColor(actualImage,cv2.COLOR_BGR2GRAY) #Converting the picture GRAY here as detection happens using gray scale\n",
    "            canvas,picture = detectFacesFromRegisteredImages(grayImage,actualImage)\n",
    "            imageName = \"{}.jpg\".format(userName + str(i))\n",
    "            try:\n",
    "                processedImage = cv2.cvtColor(picture,cv2.COLOR_BGR2GRAY)\n",
    "                success = cv2.imwrite(os.path.join(path , imageName),processedImage)\n",
    "                if not success:\n",
    "                    os.remove(os.path.join(path , imageName))\n",
    "            except:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print('Image Processing failed!')\n",
    "        track = traceback.format_exc()\n",
    "        print(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDirectoryPath = os.getcwd() + \"\\\\Training_Images\\\\\"\n",
    "\n",
    "def startLearning():\n",
    "    \n",
    "    print('Gathering training data ...')\n",
    "    \n",
    "    y=[]\n",
    "    trainingFolderInfo = {}\n",
    "    for folder in list(os.walk(trainingDirectoryPath))[0][1]:\n",
    "        userFolder = trainingDirectoryPath + '\\\\' + folder + '\\\\'\n",
    "        numberOfImages = len([imageFile for imageFile in os.listdir(userFolder) if os.path.isfile(os.path.join(userFolder, imageFile))])\n",
    "        trainingFolderInfo[folder] = numberOfImages\n",
    "    for i,folder in enumerate(trainingFolderInfo.keys()):\n",
    "        labelList = list(np.repeat(i, trainingFolderInfo[folder]))\n",
    "        y.extend(labelList)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = []\n",
    "    IMG_HEIGHT, IMG_WIDTH = 64, 64\n",
    "    for folder in list(os.walk(trainingDirectoryPath))[0][1]:\n",
    "        userFolder = trainingDirectoryPath + '\\\\' + folder + '\\\\'\n",
    "        image_files = [ imageFile for imageFile in listdir(userFolder) if isfile(join(userFolder,imageFile))]\n",
    "        x_empty = np.empty((len(image_files), IMG_HEIGHT, IMG_WIDTH), dtype='float32')\n",
    "        #x_empty = np.empty((IMG_HEIGHT, IMG_WIDTH,len(image_files)), dtype='float32')\n",
    "        for i,nameOfImage in enumerate(image_files):\n",
    "            # Read the image one by one\n",
    "            image = userFolder + nameOfImage\n",
    "            actualImage = cv2.imread(image,flags=cv2.IMREAD_UNCHANGED).astype(\"int16\").astype('float32')\n",
    "            resizedImage = cv2.resize(actualImage, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\n",
    "            # Normalizing the values of the images \n",
    "            normalizedImage = (resizedImage - np.min(resizedImage)) / (np.max(resizedImage) - np.min(resizedImage))\n",
    "            # store the final values in x_empty which is right now empty \n",
    "            x_empty[i] = normalizedImage\n",
    "            X.append(x_empty[i])\n",
    "    X = np.array(X)\n",
    "    \n",
    "    print('Training data collected!')\n",
    "    \n",
    "    # Reshaping X and y\n",
    "    y_categorical = to_categorical(y)\n",
    "    X_reshaped = X.reshape(X.shape[0],X.shape[1],X.shape[2],1)\n",
    "    \n",
    "    print('Building neural network...')\n",
    "    global classifier\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Step 1 - adding Convolution layer of input 64x64x3 (as it is RGB) with 32 filters each with size 3x3\n",
    "    classifier.add(Conv2D(64, (3, 3), input_shape = (64, 64,1), activation = 'relu'))\n",
    "\n",
    "    # Step 2 - adding the max Pooling layer\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # Adding a second convolutional layer with 32 filters each with size 3x3\n",
    "    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # Step 3 - Flattening\n",
    "    classifier.add(Flatten())\n",
    "\n",
    "    # Step 4 - Full connection\n",
    "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "    \n",
    "    classifier.add(Dense(units = len(list(os.walk(trainingDirectoryPath))[0][1]), activation = 'softmax'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    print('Neural Network created!')\n",
    "    \n",
    "    print('Neural Network starts learning...')\n",
    "    classifier.fit(x=X_reshaped,y=y_categorical,epochs=10,batch_size=2) \n",
    "    print('Learning finished!')\n",
    "    return classifier,dict(list(zip(list(np.unique(y)),list(os.walk(trainingDirectoryPath))[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizeFaceOnVideo(gray,frame):\n",
    "    faces = face_cascade.detectMultiScale(gray,1.05,6)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x-50,y-50),(x+w+50,y+h+50),(255,0,0),2)\n",
    "        region_of_interest_gray = gray[y:y+h,x:x+w]   # Cascade will be applied in gray scaled version of region of  interest\n",
    "        region_of_interest_frame = frame[y-50:y+h+50,x-50:x+w+50] # Rectangle will be drawn to colored version of area of interest\n",
    "        \n",
    "        try:\n",
    "            picture_64x64 = cv2.resize(region_of_interest_frame,(64,64),interpolation = cv2.INTER_AREA) #Resize the image to 64x64\n",
    "            picture_64x64_gray = cv2.cvtColor(picture_64x64,cv2.COLOR_BGR2GRAY) #Convert to gray\n",
    "            picture_64x64_gray_normalized =  (picture_64x64_gray - np.min(picture_64x64_gray)) / (np.max(picture_64x64_gray) - np.min(picture_64x64_gray)) #Normalize\n",
    "      \n",
    "            test_picture = np.array(picture_64x64_gray_normalized)\n",
    "            test_picture = np.expand_dims(test_picture,axis=0)\n",
    "            test_picture = test_picture.reshape(test_picture.shape[0],test_picture.shape[1],test_picture.shape[2],1)\n",
    "        \n",
    "            result = classifier.predict(test_picture)\n",
    "            \n",
    "            \n",
    "            recognizedFaceName = user_label[np.argmax(result[0])]\n",
    "            cv2.putText(region_of_interest_frame, recognizedFaceName, (x-200, y-40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "            cv2.putText(region_of_interest_frame, 'Accuracy: ' + str(round(result[0][np.argmax(result[0])]*100,2)) + '%', (x-200, y-20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (0,255,0), 2)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openCameraToRecognizeFace():\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    timeout = time.time() + 60*1   # 1 minutes from now\n",
    "    while video_capture.isOpened():\n",
    "        while True:\n",
    "            try:\n",
    "                test = 0\n",
    "                if test == 3 or time.time() > timeout:\n",
    "                    print('Disconnecting the camera!')\n",
    "                    break\n",
    "                test = test - 1\n",
    "                _,frame = video_capture.read()\n",
    "                #print(frame)\n",
    "                gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                canvas = recognizeFaceOnVideo(gray,frame)\n",
    "                cv2.imshow('Video',canvas)\n",
    "                if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "                    print('Disconnecting the camera!')\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print('Camera Failed to recognise your face!')\n",
    "                \n",
    "                track = traceback.format_exc()\n",
    "                print(track)\n",
    "                continue\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(t):\n",
    "    while t:\n",
    "        mins, secs = divmod(t, 60)\n",
    "        timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "        print(timer, end=\"\\r\")\n",
    "        time.sleep(1)\n",
    "        t -= 1\n",
    "    print('Starting Camera!!!')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDir(path):\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            pass\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    name = input('Your name: ')\n",
    "    global registerDirectoryPath\n",
    "    global trainingDirectoryPath\n",
    "    global user_label\n",
    "    registerDirectoryPath = os.getcwd() + \"\\\\Registered_Images\\\\\"\n",
    "    trainingDirectoryPath = os.getcwd() + \"\\\\Training_Images\\\\\"\n",
    "    createDir(registerDirectoryPath)\n",
    "    createDir(trainingDirectoryPath)\n",
    "    createDir(trainingDirectoryPath + '\\\\Dummy\\\\')\n",
    "    dummyImage = cv2.imread('dummyUser.jpg')\n",
    "    for i in range(0,5):\n",
    "        dummyGrayImage = cv2.cvtColor(dummyImage, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(os.path.join(trainingDirectoryPath + '\\\\Dummy\\\\', 'dummyUser{}.jpg'.format(i)),dummyGrayImage)\n",
    "    if os.path.exists(registerDirectoryPath + name):\n",
    "        print('You are already registered')\n",
    "        classifier = load_model('NN_FaceRecognitionData.h5')\n",
    "        with open(os.getcwd() + '\\\\Label_User_information.pickle', 'rb') as handle:\n",
    "            label_user_dict = pickle.load(handle)\n",
    "        user_label = label_user_dict\n",
    "        print('Loading Trained Neural Network Model...')\n",
    "        classifier = load_model('NN_FaceRecognitionData.h5')\n",
    "        print('Neural Network loaded!')\n",
    "        \n",
    "        print('Camera will open after sometime to recognise you!')\n",
    "        openCameraToRecognizeFace()\n",
    "        \n",
    "    else:\n",
    "        print('As you are not registered. Please follow as directed.')\n",
    "        print('Camera will open up to register your face!\\nRequest you to face the webcam')\n",
    "        startCountdown = int(input('Enter the timer (in seconds) here to start capturing your image: '))\n",
    "        if countdown(startCountdown):\n",
    "            print('Capturing...')\n",
    "            registerUser(name)\n",
    "        print('Processing Your Images for training...')\n",
    "        processImages(name)\n",
    "        print('Image Processing finished!')\n",
    "        print('Algorithm is learning your Image...')\n",
    "        classifier,label_user_dict = startLearning()\n",
    "        \n",
    "        if os.path.exists(os.getcwd() + \"\\\\NN_FaceRecognitionData.h5\"):\n",
    "            os.remove(os.getcwd() + \"\\\\NN_FaceRecognitionData.h5\")\n",
    "        \n",
    "        \n",
    "        if os.path.exists(os.getcwd() + \"\\\\Label_User_information.pickle\"):\n",
    "            os.remove(os.getcwd() + \"\\\\Label_User_information.pickle\")\n",
    "        \n",
    "        \n",
    "        classifier.save(\"NN_FaceRecognitionData.h5\")\n",
    "        with open(os.getcwd() + '\\\\Label_User_information.pickle', 'wb') as handle:\n",
    "            pickle.dump(label_user_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        user_label = label_user_dict\n",
    "        print('Algorithm learnt your Image!')\n",
    "        \n",
    "        print('Loading Trained Neural Network Model...')\n",
    "        classifier = load_model('NN_FaceRecognitionData.h5')\n",
    "        print('Neural Network loaded!')\n",
    "        print('Camera will open after sometime to recognise you!')\n",
    "        \n",
    "        openCameraToRecognizeFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name: Aakash\n",
      "As you are not registered. Please follow as directed.\n",
      "Camera will open up to register your face!\n",
      "Request you to face the webcam\n",
      "Enter the timer (in seconds) here to start capturing your image: 5\n",
      "Starting Camera!!!\n",
      "Capturing...\n",
      "Aakash is registered\n",
      "Processing Your Images for training...\n",
      "Image Processing finished!\n",
      "Algorithm is learning your Image...\n",
      "Gathering training data ...\n",
      "Training data collected!\n",
      "Building neural network...\n",
      "Neural Network created!\n",
      "Neural Network starts learning...\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 1.2369 - accuracy: 0.4889\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.7768 - accuracy: 0.7111\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.1998 - accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 5.2276e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 3.0015e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 1.4015e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 1.0277e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 6.6434e-05 - accuracy: 1.0000\n",
      "Learning finished!\n",
      "Algorithm learnt your Image!\n",
      "Loading Trained Neural Network Model...\n",
      "Neural Network loaded!\n",
      "Camera will open after sometime to recognise you!\n",
      "Disconnecting the camera!\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
